{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c97f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2698614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('../data/test.csv', parse_dates=['date'])\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "oil = pd.read_csv('../data/oil.csv', parse_dates=['date'])\n",
    "holidays = pd.read_csv('../data/holidays_events.csv', parse_dates=['date'])\n",
    "transactions = pd.read_csv('../data/transactions.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0fb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_df, stores_df, oil_df, holidays_df):\n",
    "    df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "    \n",
    "    oil_df['dcoilwtico'] = oil_df['dcoilwtico'].ffill()\n",
    "    df = df.merge(oil_df, on='date', how='left')\n",
    "    \n",
    "    nat_holidays = holidays_df[(holidays_df['locale'] == 'National') & \n",
    "                               (holidays_df['transferred'] == False)]\n",
    "    nat_holidays = nat_holidays.drop_duplicates('date')[['date', 'type']]\n",
    "    nat_holidays = nat_holidays.rename(columns={'type': 'holiday_type'})\n",
    "    \n",
    "    df = df.merge(nat_holidays, on='date', how='left')\n",
    "    df['is_holiday'] = df['holiday_type'].notnull().astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = prepare_data(train, stores, oil, holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e27335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dcoilwtico",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "holiday_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_holiday",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "23373a57-7cdd-4d1e-88f7-3e544a418f13",
       "rows": [
        [
         "0",
         "0",
         "2013-01-01 00:00:00",
         "1",
         "AUTOMOTIVE",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "1",
         "1",
         "2013-01-01 00:00:00",
         "1",
         "BABY CARE",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "2",
         "2",
         "2013-01-01 00:00:00",
         "1",
         "BEAUTY",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "3",
         "3",
         "2013-01-01 00:00:00",
         "1",
         "BEVERAGES",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "4",
         "4",
         "2013-01-01 00:00:00",
         "1",
         "BOOKS",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>holiday_type</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
       "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
       "\n",
       "  type  cluster  dcoilwtico holiday_type  is_holiday  \n",
       "0    D       13         NaN      Holiday           1  \n",
       "1    D       13         NaN      Holiday           1  \n",
       "2    D       13         NaN      Holiday           1  \n",
       "3    D       13         NaN      Holiday           1  \n",
       "4    D       13         NaN      Holiday           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512df6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    df['is_payday'] = ((df['day_of_month'] == 15) | (df.date.dt.is_month_end)).astype(int)\n",
    "    \n",
    "    # Lags: What was the sale 16 days ago? \n",
    "    # (We use 16 because the test set is 15 days long)\n",
    "    df['lag_16'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.shift(16))\n",
    "    df['lag_30'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.shift(30))\n",
    "    \n",
    "    # Rolling Mean: What was the average of the 7 days ending 16 days ago?\n",
    "    df['rolling_mean_7'] = df.groupby(['store_nbr', 'family'])['lag_16'].transform(lambda x: x.rolling(7).mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478e3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll train on everything before August 2017\n",
    "# And validate on the first 15 days of August 2017\n",
    "train_set = df[df['date'] < '2017-08-01'].dropna()\n",
    "val_set = df[(df['date'] >= '2017-08-01') & (df['date'] <= '2017-08-15')]\n",
    "\n",
    "# Define features and target\n",
    "features = ['store_nbr', 'onpromotion', 'dcoilwtico', 'is_holiday', \n",
    "            'day_of_week', 'is_payday', 'lag_16', 'lag_30', 'rolling_mean_7']\n",
    "target = 'sales'\n",
    "\n",
    "X_train, y_train = train_set[features], train_set[target]\n",
    "X_val, y_val = val_set[features], val_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd42f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target transformed to log scale.\n"
     ]
    }
   ],
   "source": [
    "# Apply Log Transformation to the target\n",
    "# This helps the model focus on percentage errors (better for RMSLE)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "print(\"Target transformed to log scale.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775d37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSLE: 0.7902125653221613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "# Use a small number of trees for a quick test\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and Calculate RMSLE (the competition metric)\n",
    "preds = model.predict(X_val)\n",
    "preds = np.maximum(0, preds) # Sales cannot be negative\n",
    "\n",
    "score = np.sqrt(mean_squared_log_error(y_val, preds))\n",
    "print(f\"Baseline RMSLE: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caaa5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training rows: 3000888\n",
      "Final test rows (should be 28512): 28512\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Test set similarly to Train set\n",
    "# We need to concatenate them to calculate lags correctly for the test period\n",
    "full_df = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 2. Re-apply the merging and feature logic\n",
    "# (Using the functions we defined earlier)\n",
    "full_df = prepare_data(full_df, stores, oil, holidays)\n",
    "full_df = create_features(full_df)\n",
    "\n",
    "# 3. Separate them back out\n",
    "train_final = full_df[full_df['sales'].notnull()]\n",
    "test_final = full_df[full_df['sales'].isnull()]\n",
    "\n",
    "print(f\"Final training rows: {len(train_final)}\")\n",
    "print(f\"Final test rows (should be 28512): {len(test_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d61dedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Per-Family Training for 33 families...\n",
      "âœ… Finished: AUTOMOTIVE\n",
      "âœ… Finished: BABY CARE\n",
      "âœ… Finished: BEAUTY\n",
      "âœ… Finished: BEVERAGES\n",
      "âœ… Finished: BOOKS\n",
      "âœ… Finished: BREAD/BAKERY\n",
      "âœ… Finished: CELEBRATION\n",
      "âœ… Finished: CLEANING\n",
      "âœ… Finished: DAIRY\n",
      "âœ… Finished: DELI\n",
      "âœ… Finished: EGGS\n",
      "âœ… Finished: FROZEN FOODS\n",
      "âœ… Finished: GROCERY I\n",
      "âœ… Finished: GROCERY II\n",
      "âœ… Finished: HARDWARE\n",
      "âœ… Finished: HOME AND KITCHEN I\n",
      "âœ… Finished: HOME AND KITCHEN II\n",
      "âœ… Finished: HOME APPLIANCES\n",
      "âœ… Finished: HOME CARE\n",
      "âœ… Finished: LADIESWEAR\n",
      "âœ… Finished: LAWN AND GARDEN\n",
      "âœ… Finished: LINGERIE\n",
      "âœ… Finished: LIQUOR,WINE,BEER\n",
      "âœ… Finished: MAGAZINES\n",
      "âœ… Finished: MEATS\n",
      "âœ… Finished: PERSONAL CARE\n",
      "âœ… Finished: PET SUPPLIES\n",
      "âœ… Finished: PLAYERS AND ELECTRONICS\n",
      "âœ… Finished: POULTRY\n",
      "âœ… Finished: PREPARED FOODS\n",
      "âœ… Finished: PRODUCE\n",
      "âœ… Finished: SCHOOL AND OFFICE SUPPLIES\n",
      "âœ… Finished: SEAFOOD\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. We'll store our results here\n",
    "all_test_preds = []\n",
    "all_test_ids = []\n",
    "\n",
    "# 2. Get the list of all product families (e.g., 'BEVERAGES', 'MEATS', etc.)\n",
    "families = train_final['family'].unique()\n",
    "\n",
    "print(f\"Starting Per-Family Training for {len(families)} families...\")\n",
    "\n",
    "for fam in families:\n",
    "    # Filter the data for JUST this family\n",
    "    train_fam = train_final[train_final['family'] == fam]\n",
    "    test_fam = test_final[test_final['family'] == fam]\n",
    "    \n",
    "    # Define X (features) and y (target)\n",
    "    X_train = train_fam[features]\n",
    "    \n",
    "    # --- THE TRICK ---\n",
    "    # We use np.log1p to turn sales into a log scale. \n",
    "    # This is the secret to a better RMSLE score!\n",
    "    y_train = np.log1p(train_fam['sales']) \n",
    "    \n",
    "    X_test_fam = test_fam[features]\n",
    "    \n",
    "    # 3. Train a model specifically for this family\n",
    "    model = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 4. Predict and convert back from log scale using np.expm1\n",
    "    fam_preds = np.expm1(model.predict(X_test_fam))\n",
    "    \n",
    "    # Store predictions and the matching IDs\n",
    "    all_test_preds.extend(fam_preds)\n",
    "    all_test_ids.extend(test_fam['id'])\n",
    "    \n",
    "    print(f\"âœ… Finished: {fam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c47bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ New submission file saved: ../submissions/submission_per_family.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Create the final submission file\n",
    "submission_v2 = pd.DataFrame({\n",
    "    'id': np.array(all_test_ids).astype(int),\n",
    "    'sales': np.array(all_test_preds)\n",
    "})\n",
    "\n",
    "# Sort by ID to make sure it's in the right order for Kaggle\n",
    "submission_v2 = submission_v2.sort_values('id')\n",
    "\n",
    "submission_v2.to_csv('../submissions/submission_per_family.csv', index=False)\n",
    "print(\"\\nðŸš€ New submission file saved: ../submissions/submission_per_family.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135a723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
