{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c97f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2698614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('../data/test.csv', parse_dates=['date'])\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "oil = pd.read_csv('../data/oil.csv', parse_dates=['date'])\n",
    "holidays = pd.read_csv('../data/holidays_events.csv', parse_dates=['date'])\n",
    "transactions = pd.read_csv('../data/transactions.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0fb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_df, stores_df, oil_df, holidays_df):\n",
    "    df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "    \n",
    "    oil_df['dcoilwtico'] = oil_df['dcoilwtico'].ffill()\n",
    "    df = df.merge(oil_df, on='date', how='left')\n",
    "    \n",
    "    nat_holidays = holidays_df[(holidays_df['locale'] == 'National') & \n",
    "                               (holidays_df['transferred'] == False)]\n",
    "    nat_holidays = nat_holidays.drop_duplicates('date')[['date', 'type']]\n",
    "    nat_holidays = nat_holidays.rename(columns={'type': 'holiday_type'})\n",
    "    \n",
    "    df = df.merge(nat_holidays, on='date', how='left')\n",
    "    df['is_holiday'] = df['holiday_type'].notnull().astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = prepare_data(train, stores, oil, holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e27335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dcoilwtico",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "holiday_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_holiday",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3223c04b-1572-4a9d-827b-e776b942fa10",
       "rows": [
        [
         "0",
         "0",
         "2013-01-01 00:00:00",
         "1",
         "AUTOMOTIVE",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "1",
         "1",
         "2013-01-01 00:00:00",
         "1",
         "BABY CARE",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "2",
         "2",
         "2013-01-01 00:00:00",
         "1",
         "BEAUTY",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "3",
         "3",
         "2013-01-01 00:00:00",
         "1",
         "BEVERAGES",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ],
        [
         "4",
         "4",
         "2013-01-01 00:00:00",
         "1",
         "BOOKS",
         "0.0",
         "0",
         "Quito",
         "Pichincha",
         "D",
         "13",
         null,
         "Holiday",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>holiday_type</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
       "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
       "\n",
       "  type  cluster  dcoilwtico holiday_type  is_holiday  \n",
       "0    D       13         NaN      Holiday           1  \n",
       "1    D       13         NaN      Holiday           1  \n",
       "2    D       13         NaN      Holiday           1  \n",
       "3    D       13         NaN      Holiday           1  \n",
       "4    D       13         NaN      Holiday           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512df6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # 1. Basic Time Features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # 2. Fourier Features (Captures the 7-day weekly cycle perfectly)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # 3. The Earthquake Fix (April 16, 2016)\n",
    "    # We tell the model how many weeks have passed since the disaster \n",
    "    # to help it \"forget\" the artificial spike in sales.\n",
    "    earthquake_date = pd.to_datetime('2016-04-16')\n",
    "    df['weeks_since_earthquake'] = (df['date'] - earthquake_date).dt.days // 7\n",
    "    df['weeks_since_earthquake'] = df['weeks_since_earthquake'].clip(lower=0) \n",
    "\n",
    "    # 4. Better Lags & Rolling windows\n",
    "    # We'll stick to lag_16 for safety, but add a 14-day rolling mean\n",
    "    df['lag_16'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.shift(16))\n",
    "    df['rolling_mean_14'] = df.groupby(['store_nbr', 'family'])['lag_16'].transform(lambda x: x.rolling(14).mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478e3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll train on everything before August 2017\n",
    "# And validate on the first 15 days of August 2017\n",
    "train_set = df[df['date'] < '2017-08-01'].dropna()\n",
    "val_set = df[(df['date'] >= '2017-08-01') & (df['date'] <= '2017-08-15')]\n",
    "\n",
    "# Define features and target\n",
    "features = ['store_nbr', 'onpromotion', 'dcoilwtico', 'day_of_week', \n",
    "            'day_sin', 'day_cos', 'weeks_since_earthquake', 'lag_16', 'rolling_mean_14']\n",
    "target = 'sales'\n",
    "\n",
    "X_train, y_train = train_set[features], train_set[target]\n",
    "X_val, y_val = val_set[features], val_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd42f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target transformed to log scale.\n"
     ]
    }
   ],
   "source": [
    "# Apply Log Transformation to the target\n",
    "# This helps the model focus on percentage errors (better for RMSLE)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "print(\"Target transformed to log scale.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caaa5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training rows: 3000888\n",
      "Final test rows (should be 28512): 28512\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Test set similarly to Train set\n",
    "# We need to concatenate them to calculate lags correctly for the test period\n",
    "full_df = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 2. Re-apply the merging and feature logic\n",
    "# (Using the functions we defined earlier)\n",
    "full_df = prepare_data(full_df, stores, oil, holidays)\n",
    "full_df = create_features(full_df)\n",
    "\n",
    "# 3. Separate them back out\n",
    "train_final = full_df[full_df['sales'].notnull()]\n",
    "test_final = full_df[full_df['sales'].isnull()]\n",
    "\n",
    "print(f\"Final training rows: {len(train_final)}\")\n",
    "print(f\"Final test rows (should be 28512): {len(test_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61dedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Per-Family Training for 33 families...\n",
      "Training 33 specialized LightGBM models...\n",
      "âœ… LightGBM Finished: AUTOMOTIVE\n",
      "âœ… LightGBM Finished: BABY CARE\n",
      "âœ… LightGBM Finished: BEAUTY\n",
      "âœ… LightGBM Finished: BEVERAGES\n",
      "âœ… LightGBM Finished: BOOKS\n",
      "âœ… LightGBM Finished: BREAD/BAKERY\n",
      "âœ… LightGBM Finished: CELEBRATION\n",
      "âœ… LightGBM Finished: CLEANING\n",
      "âœ… LightGBM Finished: DAIRY\n",
      "âœ… LightGBM Finished: DELI\n",
      "âœ… LightGBM Finished: EGGS\n",
      "âœ… LightGBM Finished: FROZEN FOODS\n",
      "âœ… LightGBM Finished: GROCERY I\n",
      "âœ… LightGBM Finished: GROCERY II\n",
      "âœ… LightGBM Finished: HARDWARE\n",
      "âœ… LightGBM Finished: HOME AND KITCHEN I\n",
      "âœ… LightGBM Finished: HOME AND KITCHEN II\n",
      "âœ… LightGBM Finished: HOME APPLIANCES\n",
      "âœ… LightGBM Finished: HOME CARE\n",
      "âœ… LightGBM Finished: LADIESWEAR\n",
      "âœ… LightGBM Finished: LAWN AND GARDEN\n",
      "âœ… LightGBM Finished: LINGERIE\n",
      "âœ… LightGBM Finished: LIQUOR,WINE,BEER\n",
      "âœ… LightGBM Finished: MAGAZINES\n",
      "âœ… LightGBM Finished: MEATS\n",
      "âœ… LightGBM Finished: PERSONAL CARE\n",
      "âœ… LightGBM Finished: PET SUPPLIES\n",
      "âœ… LightGBM Finished: PLAYERS AND ELECTRONICS\n",
      "âœ… LightGBM Finished: POULTRY\n",
      "âœ… LightGBM Finished: PREPARED FOODS\n",
      "âœ… LightGBM Finished: PRODUCE\n",
      "âœ… LightGBM Finished: SCHOOL AND OFFICE SUPPLIES\n",
      "âœ… LightGBM Finished: SEAFOOD\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "families = train_final['family'].unique()\n",
    "\n",
    "print(f\"Starting Per-Family Training for {len(families)} families...\")\n",
    "import lightgbm as lgb\n",
    "\n",
    "features = ['store_nbr', 'onpromotion', 'dcoilwtico', 'day_of_week', \n",
    "            'day_sin', 'day_cos', 'weeks_since_earthquake', 'lag_16', 'rolling_mean_14']\n",
    "\n",
    "all_test_preds = []\n",
    "test_ids = []\n",
    "\n",
    "print(\"Training 33 specialized LightGBM models...\")\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "}\n",
    "\n",
    "for fam in families:\n",
    "    train_fam = train_final[train_final['family'] == fam]\n",
    "    test_fam = test_final[test_final['family'] == fam]\n",
    "    \n",
    "    # Prepare datasets for LightGBM\n",
    "    dtrain = lgb.Dataset(train_fam[features], label=np.log1p(train_fam['sales']))\n",
    "    \n",
    "    # Train\n",
    "    model = lgb.train(lgb_params, dtrain, num_boost_round=200)\n",
    "    \n",
    "    # Predict\n",
    "    preds = np.expm1(model.predict(test_fam[features]))\n",
    "    \n",
    "    all_test_preds.extend(preds)\n",
    "    test_ids.extend(test_fam['id'])\n",
    "    print(f\"âœ… LightGBM Finished: {fam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c47bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ New submission file saved: ../submissions/submission_per_family.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Create the final submission file\n",
    "submission_v2 = pd.DataFrame({\n",
    "    'id': np.array(test_ids).astype(int),\n",
    "    'sales': np.array(all_test_preds)\n",
    "})\n",
    "\n",
    "# Sort by ID to make sure it's in the right order for Kaggle\n",
    "submission_v2 = submission_v2.sort_values('id')\n",
    "\n",
    "submission_v2.to_csv('../submissions/submission_per_family.csv', index=False)\n",
    "print(\"\\nðŸš€ New submission file saved: ../submissions/submission_per_family.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135a723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
